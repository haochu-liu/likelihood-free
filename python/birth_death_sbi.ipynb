{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e987e03c",
   "metadata": {},
   "source": [
    "# Test birth-death process simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88860883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error importing in API mode: ImportError('On Windows, cffi mode \"ANY\" is only \"ABI\".')\n",
      "Trying to import in ABI mode.\n",
      "c:\\Users\\u2008181\\likelihood-free\\sbi_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "import torch\n",
    "from sbi.utils.torchutils import BoxUniform\n",
    "from sbi.inference import NPE_C, simulate_for_sbi\n",
    "from sbi.utils.user_input_checks import (\n",
    "    check_sbi_inputs,\n",
    "    process_prior,\n",
    "    process_simulator,\n",
    ")\n",
    "import os\n",
    "\n",
    "os.environ['R_HOME'] = r'C:\\Program Files\\R\\R-4.5.1' # Set local R path\n",
    "torch_device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94bf156a",
   "metadata": {},
   "source": [
    "## Simulate observation value\n",
    "\n",
    "Set the true birth rate to be 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "819266ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "simARG = importr(\"simARG\")\n",
    "\n",
    "robjects.r('set.seed(100)')\n",
    "x_o = simARG.birth_death_sim2(20, 3.0)\n",
    "x_o = torch.tensor(x_o, device=torch_device)\n",
    "x_o = x_o.flatten()\n",
    "\n",
    "x_o_numpy = x_o.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fc811e",
   "metadata": {},
   "source": [
    "## Prior and simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14ca9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = BoxUniform(\n",
    "    low=torch.tensor([0.0], device=torch_device),\n",
    "    high=torch.tensor([10.0], device=torch_device), \n",
    "    device=torch_device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31c7e473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulator(theta):\n",
    "    theta = theta.reshape(-1)\n",
    "    x_o_R = simARG.birth_death_sim(20, theta.item())\n",
    "    x_o = list(x_o_R)\n",
    "    x_o = [item[0] for item in x_o]\n",
    "    x_o = torch.tensor(x_o, device=torch_device)\n",
    "    return x_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa5c1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior, num_parameters, prior_returns_numpy = process_prior(prior)\n",
    "simulator = process_simulator(simulator, prior, prior_returns_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df85535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_sbi_inputs(simulator, prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3274de12",
   "metadata": {},
   "source": [
    "## NPE-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17d24b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_budget = 5000\n",
    "seed = 100\n",
    "num_posterior_samples=1000\n",
    "learning_rate = 0.0005\n",
    "\n",
    "inference = NPE_C(prior=prior, density_estimator=\"nsf\", device=torch_device)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "362c310f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Could not pickle the task to send it to the workers.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\u2008181\\likelihood-free\\sbi_env\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\queues.py\", line 159, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\u2008181\\likelihood-free\\sbi_env\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 214, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"c:\\Users\\u2008181\\likelihood-free\\sbi_env\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 207, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"c:\\Users\\u2008181\\likelihood-free\\sbi_env\\Lib\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle.py\", line 1313, in dump\n    return super().dump(obj)\n           ^^^^^^^^^^^^^^^^^\nTypeError: cannot pickle 'InstalledSTPackage' object\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mPicklingError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m theta, x = \u001b[43msimulate_for_sbi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m=\u001b[49m\u001b[43msimulator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproposal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_simulations\u001b[49m\u001b[43m=\u001b[49m\u001b[43msimulation_budget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\u2008181\\likelihood-free\\sbi_env\\Lib\\site-packages\\sbi\\utils\\simulation_utils.py:93\u001b[39m, in \u001b[36msimulate_for_sbi\u001b[39m\u001b[34m(simulator, proposal, num_simulations, num_workers, simulation_batch_size, seed, show_progress_bar)\u001b[39m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m simulator(theta)\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:  \u001b[38;5;66;03m# catch TypeError to give more informative error message\u001b[39;00m\n\u001b[32m     91\u001b[39m     simulation_outputs: \u001b[38;5;28mlist\u001b[39m[Tensor] = \u001b[43m[\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pyright: ignore\u001b[39;49;00m\n\u001b[32m     92\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxx\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m            \u001b[49m\u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_as\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgenerator\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m                \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimulator_seeded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_seeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_simulations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    104\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFor multiprocessing, we switch to numpy arrays. Make sure to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    105\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpreprocess your simulator with `process_simulator` to handle numpy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    106\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m arrays.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    107\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\u2008181\\likelihood-free\\sbi_env\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\u2008181\\likelihood-free\\sbi_env\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\u2008181\\likelihood-free\\sbi_env\\Lib\\site-packages\\joblib\\parallel.py:1784\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1782\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1783\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1785\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1787\u001b[39m     nb_jobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\u2008181\\likelihood-free\\sbi_env\\Lib\\site-packages\\joblib\\parallel.py:1859\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1855\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1856\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1857\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\u2008181\\likelihood-free\\sbi_env\\Lib\\site-packages\\joblib\\parallel.py:758\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    752\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\u2008181\\likelihood-free\\sbi_env\\Lib\\site-packages\\joblib\\parallel.py:773\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mPicklingError\u001b[39m: Could not pickle the task to send it to the workers."
     ]
    }
   ],
   "source": [
    "theta, x = simulate_for_sbi(\n",
    "    simulator=simulator, proposal=prior, num_simulations=simulation_budget, num_workers=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f686634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
